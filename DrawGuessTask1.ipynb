{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5b2320-dfa9-4a91-9afe-49fc5f718b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch #we use the pytorch lib which is similar to numpy but we can run it on GPU for faster running and we can also use autograd to find the gradient.\n",
    "import torch.nn as nn #this is the neural network module\n",
    "'''\n",
    "    This neural network module is very important, since we can even create our model without it but then we will have to\n",
    "    manually implement everything. Without it, we will have to write our own forward pass, loss function etc.\n",
    "'''\n",
    "import torch.optim as optim #to update weights during training\n",
    "\n",
    "#to load given dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "#we can use GPU if it is available or else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f500751-506c-46f5-9300-4bc7a1541d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45000, 5000, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR-10 images are 32x32x3 RGB\n",
    "# Normalization just scales pixel values roughly to [-1, 1]\n",
    "\n",
    "#each image consists of pixel values, we convert them to tensor [255, 128, 0] → [1.0, 0.5, 0.0]\n",
    "#normalizing them will make the values fall between -1 and 1, which is easier to train the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),   # mean per channel\n",
    "                         (0.2023, 0.1994, 0.2010))   # std per channel\n",
    "])\n",
    "\n",
    "# Download/load CIFAR-10\n",
    "'''\n",
    "    The given dataset consists of 60,000 images of 10 different categories/classes. Thus we can say our model is based on Classification Learning\n",
    "    Algorithm which is a type of Supervised Learning Algorithm. Classification Learning Algorithm generally deals with classes/categories and\n",
    "    not numbers. For example, a classification algorithm with 2 outputs is known as Binary Classification and is solved using Logistic\n",
    "    Regression. \n",
    "'''\n",
    "root_dir = \"./data\"  # change if you want\n",
    "full_train_dataset = datasets.CIFAR10(root=root_dir, train=True,\n",
    "                                      transform=transform, download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir, train=False,\n",
    "                                transform=transform, download=True)\n",
    "\n",
    "# Split training set into train + validation (e.g. 45k train, 5k val)\n",
    "# that means, 45k out of 50k images are used to train the model, and rest 5k images are used to check if our model is learning something or overfitting\n",
    "# incase the model is overfitting, we will have to add regularization (task 2)\n",
    "train_size = int(0.9 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "#segragate all the images into batches of size 64\n",
    "batch_size = 64\n",
    "\n",
    "#we shuffle all the images before training them because there is a possibility that same class of images are together inside the dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a60902c-c932-4fad-97f3-5d02e4c2effa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCIFAR10CNN(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleCIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input: 3 x 32 x 32\n",
    "        '''\n",
    "            we have two blocks inside the constructor which will be initialized automatically when we create an object of this class, each\n",
    "            block consists of:\n",
    "                1. Convolutional Layer: extracts low-level features like edges, colors, textures\n",
    "                2. ReLU activation: introduces non-linearity so the network can learn complex patterns\n",
    "                                    other activation functions such as Softplus can also be used.\n",
    "                3. MaxPool: reduces image size from 32×32 → 16×16, removes noises\n",
    "\n",
    "            We define all the layers inside the constructor and are applied in the forward function.\n",
    "        '''\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)   # -> 32 x 16 x 16\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)   # -> 64 x 8 x 8\n",
    "        )\n",
    "\n",
    "        # Flatten from 64 x 8 x 8 = 4096 features\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)    # 10 classes in CIFAR-10\n",
    "\n",
    "    # gives us the flow of data through the model\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)            # raw scores (logits)\n",
    "        return x\n",
    "\n",
    "        '''\n",
    "            We don’t add activation at the end of forward pass because CrossEntropyLoss expects raw logits and already applies Softmax internally.\n",
    "            Adding an activation at the end will break the learning process and reduce accuracy.\n",
    "        '''\n",
    "\n",
    "# feed our model to device, ie- CPU/GPU\n",
    "model = SimpleCIFAR10CNN().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a202ed-8d10-423e-ab6a-4bf4ce8ac492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer \n",
    "criterion = nn.CrossEntropyLoss()                # good for multi-class classification\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01, \n",
    "                      momentum=0.9)             # simple baseline optimizer\n",
    "\n",
    "'''\n",
    "    We know that optimizer is used to update weights as mentioned above. SGD stands for Stochastic Gradient Descent. The parameters\n",
    "    inside it are:\n",
    "        1. model.parameter() --> these are your weights 'w'\n",
    "        2. learning rate (lr) --> learning rate is used to update the weights while using gradient descent. Choosing right learning rate (alpha)\n",
    "                                is essential since choosing very high learning rate will deviate the weights away from the global minimal\n",
    "                                of the cost function when plotted against w.\n",
    "        3. momentum --> to make the optimizer faster and smoother\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1adc41d0-a3f8-44a4-b59b-174bc1cdf71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()  # training mode (enables dropout/batchnorm if used)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)      #make sure to move the tensors to the device since our model is running on the device (CPU/GPU)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 1. forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 2. backward\n",
    "        '''\n",
    "            for a training set, when we are using .backward() to store the grad, we need to empty it after each iteration in the for loop\n",
    "            to store the new grad, thus we use: optimizer.zero_grad()\n",
    "        '''\n",
    "        optimizer.zero_grad()   # clear old gradients\n",
    "        loss.backward()         # compute new gradients\n",
    "        optimizer.step()        # update weights\n",
    "\n",
    "        # accumulate stats\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()   # evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #we use 'with torch.no_grad()' to stop tensor from tracking\n",
    "    with torch.no_grad():  # no gradients during validation\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)       \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bf7c9d-5107-4ed3-be12-d6b5e262d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 1.4093 | Train Acc: 49.22% || Val Loss: 1.1474 | Val Acc: 59.66%\n",
      "Epoch [2/10] Train Loss: 0.9726 | Train Acc: 65.56% || Val Loss: 0.9744 | Val Acc: 65.14%\n",
      "Epoch [3/10] Train Loss: 0.7701 | Train Acc: 72.64% || Val Loss: 0.8667 | Val Acc: 69.70%\n",
      "Epoch [4/10] Train Loss: 0.6054 | Train Acc: 78.88% || Val Loss: 0.9015 | Val Acc: 69.70%\n",
      "Epoch [5/10] Train Loss: 0.4623 | Train Acc: 83.64% || Val Loss: 0.9082 | Val Acc: 71.16%\n",
      "Epoch [6/10] Train Loss: 0.3245 | Train Acc: 88.51% || Val Loss: 0.9806 | Val Acc: 72.70%\n",
      "Epoch [7/10] Train Loss: 0.2302 | Train Acc: 91.86% || Val Loss: 1.1438 | Val Acc: 71.94%\n",
      "Epoch [8/10] Train Loss: 0.1502 | Train Acc: 94.86% || Val Loss: 1.2857 | Val Acc: 71.62%\n",
      "Epoch [9/10] Train Loss: 0.1110 | Train Acc: 96.23% || Val Loss: 1.3409 | Val Acc: 71.20%\n",
      "Epoch [10/10] Train Loss: 0.0950 | Train Acc: 96.87% || Val Loss: 1.5409 | Val Acc: 71.22%\n"
     ]
    }
   ],
   "source": [
    "# epoch is basically the number of times we want to train our model with the entire dataset.\n",
    "num_epochs = 10   # for baseline; you can increase later\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc     = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% \"\n",
    "          f\"|| Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e26f87f-36f8-4d07-9d5a-5051b8e0f230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5079 | Test Acc: 72.41%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823b153-c792-4834-a00e-ebd97051bf98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
